@unpublished{BAMI,
  title  = {Biological and Machine Intelligence (BAMI)},
  author = {Hawkins, J. and Ahmad, S. and Purdy, S. and Lavin, A.},
  note   = {Initial online release 0.4},
  url    = {https://numenta.com/resources/biological-and-machine-intelligence/},
  year   = {2016}
}

@article{AHMAD2017134,
  title    = {Unsupervised real-time anomaly detection for streaming data},
  journal  = {Neurocomputing},
  volume   = {262},
  pages    = {134 - 147},
  year     = {2017},
  note     = {Online Real-Time Learning Strategies for Data Streams},
  issn     = {0925-2312},
  doi      = {https://doi.org/10.1016/j.neucom.2017.04.070},
  url      = {http://www.sciencedirect.com/science/article/pii/S0925231217309864},
  author   = {Subutai Ahmad and Alexander Lavin and Scott Purdy and Zuha Agha},
  keywords = {Anomaly detection, Hierarchical Temporal Memory, Streaming data, Unsupervised learning, Concept drift, Benchmark dataset},
  abstract = {We are seeing an enormous increase in the availability of streaming, time-series data. Largely driven by the rise of connected real-time data sources, this data presents technical challenges and opportunities. One fundamental capability for streaming analytics is to model each stream in an unsupervised fashion and detect unusual, anomalous behaviors in real-time. Early anomaly detection is valuable, yet it can be difficult to execute reliably in practice. Application constraints require systems to process data in real-time, not batches. Streaming data inherently exhibits concept drift, favoring algorithms that learn continuously. Furthermore, the massive number of independent streams in practice requires that anomaly detectors be fully automated. In this paper we propose a novel anomaly detection algorithm that meets these constraints. The technique is based on an online sequence memory algorithm called Hierarchical Temporal Memory (HTM). We also present results using the Numenta Anomaly Benchmark (NAB), a benchmark containing real-world data streams with labeled anomalies. The benchmark, the first of its kind, provides a controlled open-source environment for testing anomaly detection algorithms on streaming data. We present results and analysis for a wide range of algorithms on this benchmark, and discuss future challenges for the emerging field of streaming analytics.}
}
@inbook{ObjectDetectionSIFT,
  author = {Fallas-Moya, Fabian and Torres-Rojas, Francisco J.},
  year   = {2018},
  month  = {01},
  pages  = {1-14},
  title  = {Object Recognition Using Hierarchical Temporal Memory},
  isbn   = {978-3-319-76260-9},
  doi    = {10.1007/978-3-319-76261-6_1}
}
@misc{HTMEncoding,
  title         = {Encoding Data for HTM Systems},
  author        = {Scott Purdy},
  year          = {2016},
  eprint        = {1602.05925},
  archiveprefix = {arXiv},
  primaryclass  = {cs.NE}
}

@inbook{MotionAnomalyDetection,
  author = {Daylidyonok, Ilya and Frolenkova, Anastasiya and Panov, Aleksandr},
  year   = {2019},
  month  = {01},
  pages  = {69-81},
  title  = {Extended Hierarchical Temporal Memory for Motion Anomaly Detection: Proceedings of the Ninth Annual Meeting of the BICA Society},
  isbn   = {978-3-319-99315-7},
  doi    = {10.1007/978-3-319-99316-4_10}
}

@misc{anomalyvideo,
  title         = {Video Anomaly Detection for Smart Surveillance},
  author        = {Sijie Zhu and Chen Chen and Waqas Sultani},
  year          = {2020},
  eprint        = {2004.00222},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{eyeencoder,
  author = {David McDougall (ctrl-z-9000-times)},
  year   = {2019},
  month  = {9},
  day    = {20},
  url    = {https://github.com/htm-community/htm.core/issues/259#issuecomment-533333336}
}
@misc{htm_predictions_count,
  author = {Sam Heiserman (sheiser1)},
  year   = {2022},
  month  = {1},
  day    = {5},
  url    = {https://discourse.numenta.org/t/htm-core-am-i-getting-prediction-density-correctly/9299}
}
@misc{cortical_region,
  author = {MRaptor},
  year   = {2016},
  month  = {6},
  url    = {https://discourse.numenta.org/t/htm-cheat-sheet/828}
}
@inproceedings{CNN_HTM,
  author    = {Y. {Zou} and Y. {Shi} and Y. {Wang} and Y. {Shu} and Q. {Yuan} and Y. {Tian}},
  booktitle = {2018 IEEE International Conference on Multimedia and Expo (ICME)},
  title     = {Hierarchical Temporal Memory Enhanced One-Shot Distance Learning for Action Recognition},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {1-6},
  doi       = {10.1109/ICME.2018.8486447}
}
  
@article{thousandbrains,
  author   = {Hawkins, Jeff and Lewis, Marcus and Klukas, Mirko and Purdy, Scott and Ahmad, Subutai},
  title    = {A Framework for Intelligence and Cortical Function Based on Grid Cells in the Neocortex},
  journal  = {Frontiers in Neural Circuits},
  volume   = {12},
  pages    = {121},
  year     = {2019},
  url      = {https://www.frontiersin.org/article/10.3389/fncir.2018.00121},
  doi      = {10.3389/fncir.2018.00121},
  issn     = {1662-5110},
  abstract = {How the neocortex works is a mystery. In this paper we propose a novel framework for understanding its function. Grid cells are neurons in the entorhinal cortex that represent the location of an animal in its environment. Recent evidence suggests that grid cell-like neurons may also be present in the neocortex. We propose that grid cells exist throughout the neocortex, in every region and in every cortical column. They define a location-based framework for how the neocortex functions. Whereas grid cells in the entorhinal cortex represent the location of one thing, the body relative to its environment, we propose that cortical grid cells simultaneously represent the location of many things. Cortical columns in somatosensory cortex track the location of tactile features relative to the object being touched and cortical columns in visual cortex track the location of visual features relative to the object being viewed. We propose that mechanisms in the entorhinal cortex and hippocampus that evolved for learning the structure of environments are now used by the neocortex to learn the structure of objects. Having a representation of location in each cortical column suggests mechanisms for how the neocortex represents object compositionality and object behaviors. It leads to the hypothesis that every part of the neocortex learns complete models of objects and that there are many models of each object distributed throughout the neocortex. The similarity of circuitry observed in all cortical regions is strong evidence that even high-level cognitive tasks are learned and represented in a location-based framework.}
}


@misc{fpn,
  title         = {Feature Pyramid Networks for Object Detection},
  author        = {Tsung-Yi Lin and Piotr Dollár and Ross Girshick and Kaiming He and Bharath Hariharan and Serge Belongie},
  year          = {2017},
  eprint        = {1612.03144},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{inceptionnet,
  title         = {Going Deeper with Convolutions},
  author        = {Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich},
  year          = {2014},
  eprint        = {1409.4842},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@article{htm_neurons,
  author   = {Hawkins, Jeff and Ahmad, Subutai},
  title    = {Why Neurons Have Thousands of Synapses, a Theory of Sequence Memory in Neocortex},
  journal  = {Frontiers in Neural Circuits},
  volume   = {10},
  pages    = {23},
  year     = {2016},
  url      = {https://www.frontiersin.org/article/10.3389/fncir.2016.00023},
  doi      = {10.3389/fncir.2016.00023},
  issn     = {1662-5110},
  abstract = {Pyramidal neurons represent the majority of excitatory neurons in the neocortex. Each pyramidal neuron receives input from thousands of excitatory synapses that are segregated onto dendritic branches. The dendrites themselves are segregated into apical, basal, and proximal integration zones, which have different properties. It is a mystery how pyramidal neurons integrate the input from thousands of synapses, what role the different dendrites play in this integration, and what kind of network behavior this enables in cortical tissue. It has been previously proposed that non-linear properties of dendrites enable cortical neurons to recognize multiple independent patterns. In this paper we extend this idea in multiple ways. First we show that a neuron with several thousand synapses segregated on active dendrites can recognize hundreds of independent patterns of cellular activity even in the presence of large amounts of noise and pattern variation. We then propose a neuron model where patterns detected on proximal dendrites lead to action potentials, defining the classic receptive field of the neuron, and patterns detected on basal and apical dendrites act as predictions by slightly depolarizing the neuron without generating an action potential. By this mechanism, a neuron can predict its activation in hundreds of independent contexts. We then present a network model based on neurons with these properties that learns time-based sequences. The network relies on fast local inhibition to preferentially activate neurons that are slightly depolarized. Through simulation we show that the network scales well and operates robustly over a wide range of parameters as long as the network uses a sparse distributed code of cellular activations. We contrast the properties of the new network model with several other neural network models to illustrate the relative capabilities of each. We conclude that pyramidal neurons with thousands of synapses, active dendrites, and multiple integration zones create a robust and powerful sequence memory. Given the prevalence and similarity of excitatory neurons throughout the neocortex and the importance of sequence memory in inference and behavior, we propose that this form of sequence memory may be a universal property of neocortical tissue.}
}

@article{cnn_invariance,
  author  = {Y. {Lecun} and L. {Bottou} and Y. {Bengio} and P. {Haffner}},
  journal = {Proceedings of the IEEE},
  title   = {Gradient-based learning applied to document recognition},
  year    = {1998},
  volume  = {86},
  number  = {11},
  pages   = {2278-2324},
  doi     = {10.1109/5.726791}
}

@article{anomaly_detection,
  title     = {Deep Learning for Anomaly Detection},
  volume    = {54},
  issn      = {1557-7341},
  url       = {http://dx.doi.org/10.1145/3439950},
  doi       = {10.1145/3439950},
  number    = {2},
  journal   = {ACM Computing Surveys},
  publisher = {Association for Computing Machinery (ACM)},
  author    = {Pang, Guansong and Shen, Chunhua and Cao, Longbing and Hengel, Anton Van Den},
  year      = {2021},
  month     = {4},
  pages     = {1–38}
}
@misc{ganomaly,
  title         = {GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training},
  author        = {Samet Akcay and Amir Atapour-Abarghouei and Toby P. Breckon},
  year          = {2018},
  eprint        = {1805.06725},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@inproceedings{htm_zeta1,
  title  = {Hierarchical Temporal Memory Concepts , Theory , and Terminology},
  author = {Jeff Hawkins and Dileep George},
  year   = {2006}
}
@misc{numenta_example_apps,
  title = {HTM Legacy Applications},
  url   = {https://numenta.com/machine-intelligence-technology/applications/}
}
@misc{htm_rogue,
  title = {Whitepaper: HTM for Rogue Behavior Detection},
  url   = {https://numenta.com/assets/pdf/whitepapers/Rogue%20Behavior%20Detection%20White%20Paper.pdf}
}
@misc{htm_geospatial,
  title = {Whitepaper: HTM for Geospatial Tracking},
  url   = {https://numenta.com/assets/pdf/whitepapers/Geospatial%20Tracking%20White%20Paper.pdf}
}
@misc{htm_finance,
  title = {Github: HTM for Finance},
  url   = {https://github.com/numenta/numenta-apps}
}
@misc{semantic_folding,
  title         = {Semantic Folding Theory And its Application in Semantic Fingerprinting},
  author        = {Francisco De Sousa Webber},
  year          = {2016},
  eprint        = {1511.08855},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}
@article{unknown_detection1,
  title    = {Anomaly Detection with Unknown Anomalies: Application to Maritime Machinery},
  journal  = {IFAC-PapersOnLine},
  volume   = {54},
  number   = {16},
  pages    = {105-111},
  year     = {2021},
  note     = {13th IFAC Conference on Control Applications in Marine Systems, Robotics, and Vehicles CAMS 2021},
  issn     = {2405-8963},
  doi      = {https://doi.org/10.1016/j.ifacol.2021.10.080},
  url      = {https://www.sciencedirect.com/science/article/pii/S2405896321014828},
  author   = {Katarzyna Michałowska and Signe Riemer-Sørensen and Camilla Sterud and Ole Magnus Hjellset},
  keywords = {anomaly detection, predictive maintenance, machine learning, condition-based monitoring, fault detection, diagnosis, grey-box modelling},
  abstract = {We present a framework for deriving anomaly detection algorithms on timeseries data when the time and expression of anomalous behaviour is unknown. The framework is suited for problems in which individual machine learning paradigms cannot be directly implemented: supervised learning is not applicable due to the lack of labelled data, unsupervised learning is not effective since the normal operations are insufficiently defined and take complex and diverse forms, and deep learning risks confusing problematic behaviours for expected ones due to the possible repetitiveness of similar anomalies. The proposed approach is comprised of two phases: unsupervised discovery of anomalies, and semi-supervised construction and tuning of the anomaly detection algorithm. By leveraging data exploration methods and expert knowledge, the resulting algorithms are interpretable and detect a wide range of anomalous behaviours. The approach is applied to the early detection of wear and tear of maritime propulsion and manoeuvring machinery. We show that the final algorithm is able to detect different types of anomalies, including an actual internal leakage in a thruster which is otherwise overlooked by the present rule-based alarm system.}
}
@article{unknown_detection2,
  author  = {Fan, Wei and Miller, Matt and Stolfo, Salvatore and Lee, Wenke and Chan, Philip},
  year    = {2001},
  month   = {10},
  pages   = {},
  title   = {Using Artificial Anomalies to Detect Unknown and Known Network Intrusions},
  volume  = {6},
  journal = {Knowledge and Information Systems},
  doi     = {10.1007/s10115-003-0132-7}
}
@inproceedings{class_imbalance1,
  author = {Devi, Debashree and Biswas, Saroj and Purkayastha, Biswajit},
  year   = {2021},
  month  = {08},
  pages  = {},
  title  = {A Review on Solution to Class Imbalance Problem: Undersampling Approaches}
}
@misc{heterogeneous1,
  title         = {Detecting Anomalies Through Contrast in Heterogeneous Data},
  author        = {Debanjan Datta and Sathappan Muthiah and Naren Ramakrishnan},
  year          = {2021},
  eprint        = {2104.01156},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@inproceedings{autoencoder1,
  title     = {Outlier Detection for Time Series with Recurrent Autoencoder Ensembles},
  author    = {Kieu, Tung and Yang, Bin and Guo, Chenjuan and Jensen, Christian S.},
  booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on
               Artificial Intelligence, {IJCAI-19}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  pages     = {2725--2732},
  year      = {2019},
  month     = {7},
  doi       = {10.24963/ijcai.2019/378},
  url       = {https://doi.org/10.24963/ijcai.2019/378}
}
@misc{noise1,
  title         = {Google's Cloud Vision API Is Not Robust To Noise},
  author        = {Hossein Hosseini and Baicen Xiao and Radha Poovendran},
  year          = {2017},
  eprint        = {1704.05051},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
@misc{noise2,
  title         = {Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
  author        = {Dan Hendrycks and Thomas Dietterich},
  year          = {2019},
  eprint        = {1903.12261},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}
@inproceedings{divergentNets,
  title     = {DivergentNets: Medical Image Segmentation by Network Ensemble},
  author    = {Thambawita, Vajira and Hicks, Steven A. and Halvorsen, P{\aa}l and Riegler, Michael A.},
  booktitle = {Proceedings of the 3rd International Workshop and Challenge on Computer Vision in Endoscopy (EndoCV 2021)
               co-located with with the 17th IEEE International Symposium on Biomedical Imaging (ISBI 2021)},
  year      = {2021}
}
@misc{htm_sp_presentation,
  author = {Yuwei Cui},
  url    = {https://numenta.github.io/numenta-web/assets/pdf/spatial-pooling-algorithm/HTM-Spatial-Pooler-Overview.pdf},
  title  = {HTM Spatial Pooler},
  year   = {2017},
  month  = {02}
}
@unknown{spiking_neural_networks,
  author = {Rafi, Taki Hasan},
  year   = {2021},
  month  = {04},
  pages  = {},
  title  = {A Brief Review on Spiking Neural Network - A Biological Inspiration},
  doi    = {10.20944/preprints202104.0202.v1}
}